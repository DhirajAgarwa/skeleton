{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "# Initialize MediaPipe Pose model\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "\n",
    "# Initialize MediaPipe drawing utilities\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Initialize VideoCapture object\n",
    "cap = cv2.VideoCapture(1)  # Change 0 to the camera index if you have multiple cameras\n",
    "\n",
    "# Get the frame width and height\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert BGR to RGB\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Process the frame with MediaPipe Pose\n",
    "    results = pose.process(rgb_frame)\n",
    "\n",
    "    # Create a black screen of the same size for each frame\n",
    "    black_screen = np.zeros((frame_height, frame_width, 3), dtype=np.uint8)\n",
    "\n",
    "    if results.pose_landmarks is not None:\n",
    "        # Draw pose landmarks on the black screen\n",
    "        mp_drawing.draw_landmarks(\n",
    "            black_screen, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "    # Display the resulting frames\n",
    "    cv2.imshow('Whole Body Detection', frame)\n",
    "    cv2.imshow('Black Screen', black_screen)\n",
    "\n",
    "    # Exit the loop when 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the VideoCapture and close all OpenCV windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scipy in c:\\users\\vishal goyal\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (1.10.0)\n",
      "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in c:\\users\\vishal goyal\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scipy) (1.24.4)\n"
     ]
    }
   ],
   "source": [
    "! pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "from scipy.spatial import Delaunay\n",
    "\n",
    "# Initialize MediaPipe Pose model\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose()\n",
    "\n",
    "# Initialize VideoCapture object\n",
    "cap = cv2.VideoCapture(1)  # Change 0 to the camera index if you have multiple cameras\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert BGR to RGB\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Process the frame with MediaPipe Pose\n",
    "    results = pose.process(rgb_frame)\n",
    "\n",
    "    if results.pose_landmarks is not None:\n",
    "        # Extract landmark coordinates\n",
    "        landmarks = np.array([[lmk.x * frame.shape[1], lmk.y * frame.shape[0]] for lmk in results.pose_landmarks.landmark])\n",
    "\n",
    "        # Perform Delaunay triangulation\n",
    "        tri = Delaunay(landmarks)\n",
    "\n",
    "        # Extract triangles\n",
    "        triangles = landmarks[tri.simplices]\n",
    "\n",
    "        # Draw triangles on frame\n",
    "        for triangle in triangles:\n",
    "            pt1, pt2, pt3 = triangle.astype(int)\n",
    "            cv2.line(frame, tuple(pt1), tuple(pt2), (0, 255, 0), 1)\n",
    "            cv2.line(frame, tuple(pt2), tuple(pt3), (0, 255, 0), 1)\n",
    "            cv2.line(frame, tuple(pt3), tuple(pt1), (0, 255, 0), 1)\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Advanced Body Scanning', frame)\n",
    "\n",
    "    # Exit the loop when 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the VideoCapture and close all OpenCV windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "# Initialize MediaPipe Pose model\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose()\n",
    "\n",
    "# Initialize VideoCapture object\n",
    "cap = cv2.VideoCapture(1)  # Change 0 to the camera index if you have multiple cameras\n",
    "\n",
    "# Get the frame width and height\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# Define the important landmarks for highlighting\n",
    "important_landmarks = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]\n",
    "\n",
    "# Function to draw skeleton\n",
    "def draw_skeleton(frame, landmarks):\n",
    "    connections = mp_pose.POSE_CONNECTIONS\n",
    "    for connection in connections:\n",
    "        start_idx, end_idx = connection\n",
    "        start_point = (int(landmarks[start_idx][0]), int(landmarks[start_idx][1]))\n",
    "        end_point = (int(landmarks[end_idx][0]), int(landmarks[end_idx][1]))\n",
    "        cv2.line(frame, start_point, end_point, (255, 255, 255), 2)\n",
    "\n",
    "# Function to draw highlighted landmarks on the black screen\n",
    "def draw_highlighted_landmarks(frame, landmarks, important_landmarks):\n",
    "    for idx, landmark in enumerate(landmarks):\n",
    "        landmark_point = (int(landmark[0]), int(landmark[1]))\n",
    "        if idx in important_landmarks:\n",
    "            cv2.circle(frame, landmark_point, 4, (0, 0, 255), -1)  # Red color for important landmarks\n",
    "        else:\n",
    "            cv2.circle(frame, landmark_point, 2, (255, 255, 255), -1)  # White color for other landmarks\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Create a black screen of the same size for each frame\n",
    "    black_screen = np.zeros((frame_height, frame_width, 3), dtype=np.uint8)\n",
    "\n",
    "    # Convert BGR to RGB\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Process the frame with MediaPipe Pose\n",
    "    results = pose.process(rgb_frame)\n",
    "\n",
    "    if results.pose_landmarks is not None:\n",
    "        # Extract landmark coordinates\n",
    "        landmarks = np.array([[lmk.x * frame.shape[1], lmk.y * frame.shape[0]] for lmk in results.pose_landmarks.landmark])\n",
    "\n",
    "        # Draw skeleton on the black screen\n",
    "        draw_skeleton(black_screen, landmarks)\n",
    "\n",
    "        # Draw highlighted landmarks on the black screen\n",
    "        draw_highlighted_landmarks(black_screen, landmarks, important_landmarks)\n",
    "\n",
    "    # Display the black screen with highlighted landmarks\n",
    "    cv2.imshow('Black Screen', black_screen)\n",
    "\n",
    "    # Display the original frame with skeleton\n",
    "    cv2.imshow('Whole Body Detection', frame)\n",
    "\n",
    "    # Exit the loop when 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the VideoCapture and close all OpenCV windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting screeninfo\n",
      "  Downloading screeninfo-0.8.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Downloading screeninfo-0.8.1-py3-none-any.whl (12 kB)\n",
      "Installing collected packages: screeninfo\n",
      "Successfully installed screeninfo-0.8.1\n"
     ]
    }
   ],
   "source": [
    "! pip install screeninfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'frame_height' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 62>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;66;03m# Create a black screen of the same size for each frame\u001b[39;00m\n\u001b[1;32m---> 68\u001b[0m black_screen \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((\u001b[43mframe_height\u001b[49m, frame_width, \u001b[38;5;241m3\u001b[39m), dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39muint8)\n\u001b[0;32m     70\u001b[0m \u001b[38;5;66;03m# Convert BGR to RGB\u001b[39;00m\n\u001b[0;32m     71\u001b[0m rgb_frame \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(frame, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'frame_height' is not defined"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "# Initialize MediaPipe Pose and Hand models\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_hands = mp.solutions.hands\n",
    "pose = mp_pose.Pose()\n",
    "hands = mp_hands.Hands(static_image_mode=False, max_num_hands=2, min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "\n",
    "import screeninfo\n",
    "\n",
    "# Get the resolution of the primary display\n",
    "screen = screeninfo.get_monitors()[0]\n",
    "screen_width = screen.width\n",
    "screen_height = screen.height\n",
    "\n",
    "# Initialize VideoCapture object with the display resolution\n",
    "cap = cv2.VideoCapture(0)  # Change 0 to the camera index if you have multiple cameras\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, screen_width)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, screen_height)\n",
    "\n",
    "# Define the important landmarks for highlighting\n",
    "important_landmarks = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16,\n",
    "                       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31,\n",
    "                       32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46,\n",
    "                       47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59]\n",
    "\n",
    "# Define finger landmark indices\n",
    "finger_indices = [[0, 1, 2, 3, 4],   # Thumb\n",
    "                  [0, 5, 6, 7, 8],   # Index finger\n",
    "                  [0, 9, 10, 11, 12],  # Middle finger\n",
    "                  [0, 13, 14, 15, 16],  # Ring finger\n",
    "                  [0, 17, 18, 19, 20]]  # Little finger\n",
    "\n",
    "# Function to draw skeleton\n",
    "def draw_skeleton(frame, landmarks):\n",
    "    connections = mp_pose.POSE_CONNECTIONS\n",
    "    for connection in connections:\n",
    "        start_idx, end_idx = connection\n",
    "        start_point = (int(landmarks[start_idx][0]), int(landmarks[start_idx][1]))\n",
    "        end_point = (int(landmarks[end_idx][0]), int(landmarks[end_idx][1]))\n",
    "        cv2.line(frame, start_point, end_point, (255, 255, 255), 2)\n",
    "\n",
    "# Function to draw highlighted landmarks on the black screen\n",
    "def draw_highlighted_landmarks(frame, landmarks, important_landmarks):\n",
    "    for idx, landmark in enumerate(landmarks):\n",
    "        landmark_point = (int(landmark[0]), int(landmark[1]))\n",
    "        if idx in important_landmarks:\n",
    "            cv2.circle(frame, landmark_point, 4, (0, 0, 255), -1)  # Red color for important landmarks\n",
    "        else:\n",
    "            cv2.circle(frame, landmark_point, 1, (255, 255, 255), -1)  # White color for other landmarks\n",
    "\n",
    "# Function to draw fingers\n",
    "def draw_fingers(frame, landmarks, finger_indices):\n",
    "    for finger_index in finger_indices:\n",
    "        for i in range(len(finger_index) - 1):\n",
    "            start_point = (int(landmarks[finger_index[i]][0]), int(landmarks[finger_index[i]][1]))\n",
    "            end_point = (int(landmarks[finger_index[i + 1]][0]), int(landmarks[finger_index[i + 1]][1]))\n",
    "            cv2.line(frame, start_point, end_point, (255, 255, 255), 2)  # White color for finger lines\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Create a black screen of the same size for each frame\n",
    "    black_screen = np.zeros((frame_height, frame_width, 3), dtype=np.uint8)\n",
    "\n",
    "    # Convert BGR to RGB\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Process the frame with MediaPipe Pose and Hand models\n",
    "    pose_results = pose.process(rgb_frame)\n",
    "    hand_results = hands.process(rgb_frame)\n",
    "\n",
    "    # Draw pose landmarks on the black screen\n",
    "    if pose_results.pose_landmarks is not None:\n",
    "        pose_landmarks = np.array([[lmk.x * frame.shape[1], lmk.y * frame.shape[0]] for lmk in pose_results.pose_landmarks.landmark])\n",
    "        draw_skeleton(black_screen, pose_landmarks)\n",
    "        draw_highlighted_landmarks(black_screen, pose_landmarks, important_landmarks)\n",
    "\n",
    "    # Draw hand landmarks and fingers on the black screen\n",
    "    if hand_results.multi_hand_landmarks:\n",
    "        for hand_landmarks in hand_results.multi_hand_landmarks:\n",
    "            hand_landmarks = np.array([[lmk.x * frame.shape[1], lmk.y * frame.shape[0]] for lmk in hand_landmarks.landmark])\n",
    "            draw_highlighted_landmarks(black_screen, hand_landmarks, important_landmarks)\n",
    "            draw_fingers(black_screen, hand_landmarks, finger_indices)\n",
    "\n",
    "    # Display the black screen with highlighted landmarks\n",
    "    cv2.imshow('Black Screen', black_screen)\n",
    "\n",
    "    # Display the original frame with skeleton\n",
    "    # cv2.imshow('Whole Body Detection', frame)\n",
    "\n",
    "    # Exit the loop when 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the VideoCapture and close all OpenCV windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "#handssssss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "# Initialize MediaPipe Pose, Hand, and Face models\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_face = mp.solutions.face_detection\n",
    "pose = mp_pose.Pose()\n",
    "hands = mp_hands.Hands(static_image_mode=False, max_num_hands=2, min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "face_detection = mp_face.FaceDetection(min_detection_confidence=0.5)\n",
    "\n",
    "# Initialize VideoCapture object\n",
    "cap = cv2.VideoCapture(1)  # Change 0 to the camera index if you have multiple cameras\n",
    "\n",
    "# Get the frame width and height\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# Convert POSE_CONNECTIONS to a list\n",
    "POSE_CONNECTIONS = list(mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "# Define the important landmarks for highlighting\n",
    "important_landmarks = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16,\n",
    "                       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31,\n",
    "                       32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46,\n",
    "                       47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59]\n",
    "\n",
    "# Define finger landmark indices\n",
    "finger_indices = [[0, 1, 2, 3, 4],   # Thumb\n",
    "                  [0, 5, 6, 7, 8],   # Index finger\n",
    "                  [0, 9, 10, 11, 12],  # Middle finger\n",
    "                  [0, 13, 14, 15, 16],  # Ring finger\n",
    "                  [0, 17, 18, 19, 20]]  # Little finger\n",
    "\n",
    "# Convert connections to a list\n",
    "FACE_CONNECTIONS = [[0, 1], [1, 2], [2, 3], [3, 4], [4, 5], [5, 6], [6, 7], [7, 8], [8, 9], [9, 10],\n",
    "                    [10, 11], [11, 12], [12, 13], [13, 14], [14, 15], [15, 16], [16, 17], [17, 18], [18, 0], [19, 20],\n",
    "                    [20, 21], [21, 22], [22, 23], [23, 24], [24, 25], [25, 26], [26, 27], [27, 28], [28, 29], [29, 30],\n",
    "                    [30, 31], [31, 32], [32, 33], [33, 34], [34, 35], [35, 36], [36, 37], [37, 38], [38, 39], [39, 40],\n",
    "                    [40, 41], [41, 42], [42, 19], [43, 44], [44, 45], [45, 46], [46, 47], [47, 48], [48, 49], [49, 50],\n",
    "                    [50, 51], [51, 52], [52, 53], [53, 54], [54, 55], [55, 56], [56, 57], [57, 58], [58, 59], [59, 60],\n",
    "                    [60, 61], [61, 62], [62, 63], [63, 64], [64, 43]]\n",
    "\n",
    "# Function to draw skeleton\n",
    "def draw_skeleton(frame, landmarks):\n",
    "    connections = [(0, 1), (1, 14), (14, 16), (16, 18), (15, 17), (17, 19), (0, 2), (2, 3), (3, 4), (4, 6), (5, 7), (7, 9),\n",
    "                   (6, 8), (8, 10), (11, 13), (12, 14), (23, 24), (11, 23), (12, 24), (11, 12)]\n",
    "    for connection in connections:\n",
    "        start_idx, end_idx = connection\n",
    "        start_point = (int(landmarks[start_idx][0]), int(landmarks[start_idx][1]))\n",
    "        end_point = (int(landmarks[end_idx][0]), int(landmarks[end_idx][1]))\n",
    "        cv2.line(frame, start_point, end_point, (255, 255, 255), 2)\n",
    "\n",
    "# Function to draw highlighted landmarks on the black screen\n",
    "def draw_highlighted_landmarks(frame, landmarks, important_landmarks):\n",
    "    for idx, landmark in enumerate(landmarks):\n",
    "        landmark_point = (int(landmark[0]), int(landmark[1]))\n",
    "        if idx in important_landmarks:\n",
    "            cv2.circle(frame, landmark_point, 4, (0, 0, 255), -1)  # Red color for important landmarks\n",
    "        else:\n",
    "            cv2.circle(frame, landmark_point, 1, (255, 255, 255), -1)  # White color for other landmarks\n",
    "\n",
    "# Function to draw fingers\n",
    "def draw_fingers(frame, landmarks, finger_indices):\n",
    "    for finger_index in finger_indices:\n",
    "        for i in range(len(finger_index) - 1):\n",
    "            start_point = (int(landmarks[finger_index[i]][0]), int(landmarks[finger_index[i]][1]))\n",
    "            end_point = (int(landmarks[finger_index[i + 1]][0]), int(landmarks[finger_index[i + 1]][1]))\n",
    "            cv2.line(frame, start_point, end_point, (255, 255, 255), 2)  # White color for finger lines\n",
    "\n",
    "# Function to draw face landmarks\n",
    "def draw_face_landmarks(frame, face_landmarks):\n",
    "    if len(face_landmarks) >= max([max(connection) for connection in FACE_CONNECTIONS]):\n",
    "        for connection in FACE_CONNECTIONS:\n",
    "            start_point = (int(face_landmarks[connection[0]][0]), int(face_landmarks[connection[0]][1]))\n",
    "            end_point = (int(face_landmarks[connection[1]][0]), int(face_landmarks[connection[1]][1]))\n",
    "            cv2.line(frame, start_point, end_point, (0, 255, 0), 2)\n",
    "\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Create a black screen of the same size for each frame\n",
    "    black_screen = np.zeros((frame_height, frame_width, 3), dtype=np.uint8)\n",
    "\n",
    "    # Convert BGR to RGB\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Process the frame with MediaPipe Pose, Hand, and Face models\n",
    "    pose_results = pose.process(rgb_frame)\n",
    "    hand_results = hands.process(rgb_frame)\n",
    "    face_results = face_detection.process(rgb_frame)\n",
    "\n",
    "    # Draw pose landmarks on the black screen\n",
    "    if pose_results.pose_landmarks is not None:\n",
    "        pose_landmarks = np.array([[lmk.x * frame.shape[1], lmk.y * frame.shape[0]] for lmk in pose_results.pose_landmarks.landmark])\n",
    "        draw_skeleton(black_screen, pose_landmarks)\n",
    "        draw_highlighted_landmarks(black_screen, pose_landmarks, important_landmarks)\n",
    "\n",
    "    # Draw hand landmarks and fingers on the black screen\n",
    "    if hand_results.multi_hand_landmarks:\n",
    "        for hand_landmarks in hand_results.multi_hand_landmarks:\n",
    "            hand_landmarks = np.array([[lmk.x * frame.shape[1], lmk.y * frame.shape[0]] for lmk in hand_landmarks.landmark])\n",
    "            draw_highlighted_landmarks(black_screen, hand_landmarks, important_landmarks)\n",
    "            draw_fingers(black_screen, hand_landmarks, finger_indices)\n",
    "\n",
    "    # Draw face landmarks on the frame\n",
    "    if face_results.detections:\n",
    "        for detection in face_results.detections:\n",
    "            face_landmarks = np.array([[lmk.x * frame_width, lmk.y * frame_height] for lmk in detection.location_data.relative_keypoints])\n",
    "            draw_face_landmarks(frame, face_landmarks)\n",
    "\n",
    "    # Display the black screen with highlighted landmarks\n",
    "    cv2.imshow('Black Screen', black_screen)\n",
    "\n",
    "    # Display the original frame with skeleton\n",
    "    cv2.imshow('Whole Body Detection', frame)\n",
    "\n",
    "    # Exit the loop when 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the VideoCapture and close all OpenCV windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
